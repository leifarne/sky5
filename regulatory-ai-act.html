<style>
    body {
        margin: 30px;
        font-family: 'Roboto', sans-serif;
    }

    h1 {
        text-align: center;
    }

    h2 {
        color: #A33F1F
    }

    table {
        margin: 10;
        /* width: 700px; */
    }

    td {
        background-color: #246379;
        color: white;
        /* background-color: #C3D9D7; */
        padding: 16;
        vertical-align: middle;
    }

    blockquote {
        background-color: #fcf2eb;
        padding: 16;
    }
</style>

<body>
    <h1>What is the AI Act?</h1>

    <p></p>

</body>


<h1> Introduction to EU's AI Act</h1>

<h3> The AI Act is primarily a product safety regulation. This means that the regulation aims to ensure that AI systems placed, offered, or used within the EU market are reliable. The purpose of the AI Act is to promote the uptake of human-centric and trustworthy AI, while ensuring a high level of protection of health, safety, fundamental rights against harmful effects of AI system in the Union and supporting innovation.</h3>

<h2> A risk based approach</h2>

<p> The AI Act lays down a <strong> risk-based approach </strong> when categorizing AI systems into four different risk categories, with varying degrees of requirements. This approach acknowledges that not all AI systems pose the same level of risk and tailors regulations accordingly.</p>

<p>While some AI systems may represent a huge risk that the AI Act prohibits them, others are considered to have limited or minimal risk, requiring only a few obligations. The main part of AI Act focuses is obligations related to high-risk AI systems. It must be noted that only a few AI systems will be categorized as high-risk.</p>

<Strong> AI system definition </Strong>



<blockquote> <strong>AI system</strong> means a <strong>machine-based system</strong> that is designed to operate with <strong>varying
levels of autonomy</strong> and that may <strong>exhibit adaptiveness after deployment</strong>, and that, for
explicit or implicit objectives, <strong>infers, from the input it receives, how to generate outputs</strong>
such as <strong>predictions, content, recommendations, or decisions that can influence physical
or virtual environments.</strong></blockquote>

<h2> AI Act categorises AI according to its risk:</h2>
<ul> 
    <li> <strong> Unacceptable risk:</strong> Unacceptable risk is prohibited. AI systems that are unacceptable are for example social scoring systems, emotion recognition systems for law enforcement, manipulative AI, predictiv profiling in law enforecement, infer people's emotions in workplace or educational institutions, use of bimetric categorisation systems in most cases, etc .</li> 
   
 <li><strong> High risk AI system:</strong> 
An AI system is considered high-risk if it is: a. The AI systems is intented to be used as a safety part of a product or is itself a product that falls under specific EU safety rules (listed in Annex I of the AI Act), and b. 
That product, or the AI system itself, needs to be checked by an independent expert before it can be sold or used, according to those EU safety rules. c. In addition, AI systems included in AI Act Annex III.</li>

    <blockquote> High risk AI systems in Annex III</blockquote>
    

    <p>  </p>
    
    <li><strong> Limited risk AI system:</strong> </li>
    <li><strong> Minmal risk AI system:</strong> </li>
    <li><strong> Outside the scope of AI </strong> </li>

</ul>

<h2> Value Chain </h2> 


<h2> Requirements for High Risk AI systems </h2>

<h2> Requirements for Limited Risk AI systems </h2></h>

<h2> General Purpose AI systems (GPAI) </h2> 


